# 评估 (Evals)

评估 (evals) 帮助您跟踪代理行为随时间的变化。
当您将对话保存为评估后，可以稍后重放它，以查看代理的响应是否不同。评估衡量的是一致性，而不是正确性——它们告诉您行为是否发生了变化，而不是判断其对错。

## 什么是评估

评估是您可以重放的已保存对话。当您运行评估时，cagent 会重放用户消息，并将新的响应与原始保存的对话进行比较。高分意味着代理行为相似；低分意味着行为发生了变化。

您如何处理这些信息取决于您保存对话的原因。您可能保存成功的对话以捕获回归，或者保存失败案例以记录已知问题并跟踪其是否得到改善。

## 常见工作流

您如何使用评估取决于您想要完成什么：

**回归测试**：保存代理表现良好的对话。当您稍后进行更改（升级模型、更新提示、重构代码）时，运行评估。高分意味着行为保持一致，这通常是您想要的。低分意味着发生了变化——检查新行为以确认其是否仍然正确。

**跟踪改进**：保存代理表现挣扎或失败的对话。随着您进行改进，运行这些评估以查看行为如何演变。低分表明代理现在的行为不同了，这可能意味着您已经修复了问题。您需要手动验证新行为是否确实更好。

**记录边缘情况**：无论质量如何，保存有趣或不寻常的对话。使用它们来了解您的代理如何处理边缘情况，以及这种行为是否随时间变化。

评估衡量的是行为是否发生了变化。由您来判断这种变化是好是坏。

## 创建评估

从交互式会话中保存对话：

```console
$ cagent run ./agent.yaml
```

与您的代理进行对话，然后将其保存为评估：

```console
> /eval test-case-name
Eval saved to evals/test-case-name.json
```

对话会保存到您当前工作目录的 `evals/` 目录中。如果需要，您可以在子目录中组织评估文件。

## 运行评估

运行默认目录中的所有评估：

```console
$ cagent eval ./agent.yaml
```

使用自定义评估目录：

```console
$ cagent eval ./agent.yaml ./my-evals
```

针对注册表中的代理运行评估：

```console
$ cagent eval agentcatalog/myagent
```

输出示例：

```console
$ cagent eval ./agent.yaml
--- 0
First message: tell me something interesting about kil
Eval file: c7e556c5-dae5-4898-a38c-73cc8e0e6abe
Tool trajectory score: 1.000000
Rouge-1 score: 0.447368
Cost: 0.00
Output tokens: 177
```

## 理解结果

对于每个评估，cagent 会显示：

- **First message** - 保存对话中的初始用户消息
- **Eval file** - 正在运行的评估文件的 UUID
- **Tool trajectory score** - 代理使用工具的相似程度（0-1 范围，越高越好）
- **[ROUGE-1](https://en.wikipedia.org/wiki/ROUGE_(metric)) score** - 响应之间的文本相似度（0-1 范围，越高越好）
- **Cost** - 本次评估运行的成本
- **Output tokens** - 生成的令牌数量

分数越高，意味着代理的行为与原始记录的对话越相似。分数为 1.0 表示行为完全相同。

### 分数的含义

**Tool trajectory score** 衡量代理是否以与原始对话相同的顺序调用了相同的工具。较低的分数可能表明代理找到了解决问题的不同方法，这不一定错误，但值得调查。

**Rouge-1 score** 衡量响应文本与原始文本的相似程度。这是一种启发式衡量标准——不同的措辞可能仍然是正确的，因此请将其视为一种信号，而非绝对真理。

### 解释您的结果

分数接近 1.0 意味着您的更改保持了行为的一致性——代理使用相同的方法并产生相似的响应。这通常是好的；您的更改没有破坏现有功能。

较低的分数意味着与保存的对话相比，行为发生了变化。这可能是代理现在表现更差的回归，也可能是代理找到了更好方法的改进。

当分数下降时，检查实际行为以确定它是更好还是更差。评估文件以 JSON 格式存储在您的评估目录中——打开文件查看原始对话。然后使用相同的输入测试您修改后的代理以比较响应。如果新响应更好，请保存新的对话以替换评估。如果更差，那么您就发现了一个回归。

分数会引导您找到发生变化的地方。您的判断决定了变化是好是坏。

## 何时使用评估

评估帮助您跟踪行为随时间的变化。它们对于在升级模型或依赖项时捕获回归、记录您想要修复的已知失败案例以及了解边缘情况在迭代过程中的演变非常有用。

评估不适用于确定哪种代理配置最有效——它们衡量的是与保存对话的相似性，而不是正确性。使用手动测试来评估不同的配置并决定哪种更好。

保存值得跟踪的对话。构建重要工作流、有趣边缘情况和已知问题的集合。在进行更改时运行您的评估，以查看发生了什么变化。

## 下一步

- 查看 [CLI 参考](reference/cli.md#eval) 了解所有 `cagent eval` 选项
- 学习构建有效代理的[最佳实践](best-practices.md)
- 查看不同代理类型的[示例配置](https://github.com/docker/cagent/tree/main/examples)
